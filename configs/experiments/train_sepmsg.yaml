# sample style training script
dataset_path: '/home/jz4725/topomap' # dataset dir on hpc
# sample style training script
device: 0
pp_threshold: 0.0
object_threshold: 0.0
# coefficients for multitasking loss
loss_params:
  pr: 1.0
  obj: 1.0
  tcr: 0.05
  mean: 0.05

eval_split: mini-val
train_split: Training

output_dir: './exp-results/sep-multivid' #'../topomap-example-data/',
output_file: 'train'
wandb: True

# if resume training from a chkpt
resume: False
resume_path: './exp-results/train/2024-03-31_03-03-21/checkpoints/0-step3200+.pth'

eval_output_dir: '/home/jz4725/msg/exp-results/sep-multivid/2024-04-28_01-26-04' # this is specific to trained checkpoints
eval_chkpt: 23-step17976+.pth #null for no checkpoint
save_every: False # if save specific results for every video
# to enable eval during training, set eval_step > 0
eval_step: 300

learning_rate: 0.00005
num_epochs: 30
warmup_epochs: 3
warmup: cos

num_workers: 4
train_bs: 192
bs_video: 3 # number of videos per batch
eval_bs: 64 # debug test

log_every: 1
chkpt_every: 3000

obj_embedder:
  model: "dinov2-base" #"dinov2-small-mean", "dinov2-small-cls", "convnext-tiny-224", #'resnet50', # "dinov2_vits14", "dinov2_vitb14", "dinov2_vitl14", "dinov2_vitg14"
  weights: DEFAULT
  freeze: True
  output_type: mean

place_embedder:
  model: "dinov2-base" #"convnext-tiny", #'resnet50', # "dinov2_vits14", "dinov2_vitb14", "dinov2_vitl14", "dinov2_vitg14"
  weights: DEFAULT
  freeze: True
  output_type: cls # mean, cls, feature

associator:
  model: "SepMSG-linear" # ""SepMSG-linear"
  object_dim: 768 # FYI dinov2-small 384, dinov2-base 768
  place_dim: 768
  output_dim: 2048

# loss terms
pr_loss: mse
obj_loss: mse
# pos_weight: 10
# pp_weight: 1